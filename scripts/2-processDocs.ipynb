{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "- Here we will bring documentation to pages that reference other pages for documentation. <br />\n",
    "For example: extractedData/v13.5.0/app/api-reference/components/index.mdx\n",
    "\n",
    "- We will also remove comments present in the file and remove the irrelevant documentation(<>) part as well. <br />\n",
    "For example: extractedData/v13.5.0/app/building-your-application/index.mdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./processedDocs\"\n",
    "# must be a directory in current folder and should not contain any os.path.sep symbols.\n",
    "extracted_data = \"extractedData\"\n",
    "staging_data = \"stagingData\"\n",
    "\n",
    "chunk_count = 0\n",
    "# Keeps track of all the metadata_tags across all files\n",
    "metadata_tags = set()\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "if not os.path.exists(staging_data):\n",
    "    os.mkdir(staging_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_markdown(content: str) -> List[str]:\n",
    "    heading_pattern = r\"^(#{1,6})\\s+(.+)$\"\n",
    "    \n",
    "    def get_chunks(text, max_size, headings_stack):\n",
    "        \"\"\"Recursive function to chunk the markdown based on heading levels.\"\"\"\n",
    "        chunks = []\n",
    "        lines = text.splitlines()\n",
    "        buffer = []\n",
    "        current_heading = \"\"\n",
    "        in_code_block = False\n",
    "\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"```\"):\n",
    "                in_code_block = not in_code_block\n",
    "\n",
    "            if not in_code_block:\n",
    "                heading_match = re.match(heading_pattern, line)\n",
    "                if heading_match:\n",
    "                    if buffer:\n",
    "                        # Process the current buffer as a chunk\n",
    "                        chunks += split_buffer(buffer, max_size, headings_stack)\n",
    "                        buffer = []\n",
    "\n",
    "                    current_heading = heading_match.group(0)  # Full heading with level\n",
    "                    current_heading_level = len(heading_match.group(1))\n",
    "\n",
    "                    # Only adjust the headings stack up to the current heading level\n",
    "                    while (\n",
    "                        len(headings_stack) > 0 and \n",
    "                        current_heading_level <= len(re.match(heading_pattern, headings_stack[-1]).group(1))\n",
    "                    ):\n",
    "                        headings_stack = headings_stack[:-1]\n",
    "\n",
    "                    headings_stack.append(current_heading)\n",
    "                    continue\n",
    "\n",
    "            buffer.append(line)\n",
    "\n",
    "        if buffer:\n",
    "            # Process remaining buffer\n",
    "            chunks += split_buffer(buffer, max_size, headings_stack)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def split_buffer(buffer, max_size, headings_stack):\n",
    "        \"\"\"Split buffer content into chunks if it exceeds the size.\"\"\"\n",
    "        chunks = []\n",
    "        content = \"\\n\".join(buffer)\n",
    "        words = content.split()\n",
    "\n",
    "        if len(words) <= max_size:\n",
    "            chunk_content = \"\\n\".join(headings_stack).strip() + \"\\n\" + content\n",
    "            # Skip chunks that are just headings\n",
    "            if not all(re.match(heading_pattern, line) for line in content.splitlines()):\n",
    "                chunks.append(chunk_content)\n",
    "        else:\n",
    "            current_chunk = []\n",
    "            word_count = 0\n",
    "\n",
    "            for word in words:\n",
    "                current_chunk.append(word)\n",
    "                word_count += 1\n",
    "                if word_count >= max_size:\n",
    "                    # Ensure we don't split in the middle of a code block or list\n",
    "                    joined_chunk = \" \".join(current_chunk)\n",
    "                    if re.search(r\"```\", joined_chunk) and joined_chunk.count(\"```\") % 2 != 0:\n",
    "                        continue\n",
    "                    if re.search(r\"\\n\\s*[-*]\\s\", joined_chunk):\n",
    "                        continue\n",
    "\n",
    "                    chunk_content = \"\\n\".join(headings_stack).strip() + \"\\n\" + \" \".join(current_chunk)\n",
    "                    chunks.append(chunk_content)\n",
    "                    current_chunk = []\n",
    "                    word_count = 0\n",
    "\n",
    "            if current_chunk:\n",
    "                chunk_content = \"\\n\".join(headings_stack).strip() + \"\\n\" + \" \".join(current_chunk)\n",
    "                chunks.append(chunk_content)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    if not content.strip():\n",
    "        return []\n",
    "\n",
    "    return get_chunks(content, 385, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputPath(path):\n",
    "    return path.replace(\n",
    "        extracted_data + os.path.sep, \n",
    "        output_dir + os.path.sep\n",
    "    )\n",
    "\n",
    "\n",
    "def getRouter(path):\n",
    "    path_dirs = path.split(os.path.sep)\n",
    "    if extracted_data in path_dirs:\n",
    "        root_idx = path_dirs.index(extracted_data)\n",
    "        # +1 is version and +2 is the first folder inside the root.\n",
    "        return None if path_dirs[root_idx + 2] not in [\"app\", \"pages\"] else path_dirs[root_idx + 2]\n",
    "    \n",
    "    return path_dirs[0]\n",
    "\n",
    "\n",
    "def getPathFromSource(curr_path, source_path):\n",
    "    if source_path.startswith(\"'\") and source_path.endswith(\"'\"):\n",
    "        source_path = source_path[1:-1]\n",
    "\n",
    "    curr_path_folders = curr_path.split(os.path.sep)\n",
    "    base_path = os.path.sep.join(curr_path_folders[:curr_path_folders.index(getRouter(curr_path))])\n",
    "    abs_source_path = os.path.sep.join([base_path, source_path])\n",
    "\n",
    "    if os.path.isdir(abs_source_path):\n",
    "        abs_source_file = os.path.join(abs_source_path, \"index.mdx\")\n",
    "        if not os.path.isdir(abs_source_file) and os.path.exists(abs_source_file):\n",
    "            return abs_source_file\n",
    "    elif not abs_source_path.endswith(\".mdx\"):\n",
    "        return abs_source_path + \".mdx\"\n",
    "\n",
    "    return abs_source_path\n",
    "\n",
    "\n",
    "def filterRouterContent(content, router):\n",
    "    # Get the tag for current router.\n",
    "    tag = \"<AppOnly>\" if router == \"app\" else \"<PagesOnly>\"\n",
    "    remove_tag = \"<AppOnly>\" if tag == \"<PagesOnly>\" else \"<PagesOnly>\"\n",
    "\n",
    "    remove_pattern = fr'{remove_tag}(.*?)<\\/{remove_tag[1:]}'\n",
    "\n",
    "    # Remove the content of other router.\n",
    "    content = re.sub(remove_pattern, '', content, flags=re.DOTALL)\n",
    "\n",
    "    # Remove opening and closing tags of the current router.\n",
    "    content = re.sub(fr'{tag}', '', content, flags=re.DOTALL)\n",
    "    content = re.sub(fr'<\\/{tag[1:]}', '', content, flags=re.DOTALL)\n",
    "\n",
    "    content = re.sub(r'\\n{3,}', '\\n', content, flags=re.DOTALL)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def processFile(path):\n",
    "    global metadata_tags\n",
    "    content = \"\"\n",
    "    with open(path, 'r', encoding='utf-8') as fp:\n",
    "        content = fp.read()\n",
    "\n",
    "    # See if there is a source mentioned for this document.\n",
    "    lines = content.strip().split(\"\\n\")\n",
    "    metadata_lines = lines[1:lines.index(\"---\", 1)]\n",
    "    source_index = next((i for i, s in enumerate(metadata_lines) if s.startswith(\"source:\")), None)\n",
    "\n",
    "    # If there is a source mentioned.\n",
    "    if source_index is not None:\n",
    "        source_path = metadata_lines[source_index].split(\":\")[-1].strip().replace(\"/\", os.path.sep)\n",
    "        try:\n",
    "            source_path = getPathFromSource(path, source_path)\n",
    "            with open(source_path, 'r', encoding='utf-8') as fp:\n",
    "                content = fp.read()\n",
    "            \n",
    "            lines = content.strip().split(\"\\n\")\n",
    "            metadata_lines = lines[1:lines.index(\"---\", 1)]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    metadata_dict = yaml.safe_load(\"\\n\".join(metadata_lines))\n",
    "    metadata_tags = metadata_tags.union(set(metadata_dict.keys()))\n",
    "\n",
    "    # Remove metadata tag we have everything we need.\n",
    "    content = \"\\n\".join(content.split(\"\\n\")[len(metadata_lines) + 2:])\n",
    "\n",
    "    # Get rid of comments\n",
    "    content = re.sub(r'{\\/\\*.*?\\*\\/}', '', content, flags=re.DOTALL)\n",
    "    # Get rid of 3 or more consecutive newline characters.\n",
    "    content = re.sub(r'\\n{3,}', '\\n', content, flags=re.DOTALL)\n",
    "    content = content.strip()\n",
    "\n",
    "    # If no source is mentioned and file doesn't contain any content exclude it from indexing.\n",
    "    if len(metadata_lines) + 2 == len(lines):\n",
    "        return None, None, None\n",
    "        \n",
    "    router = getRouter(path)\n",
    "    if router is not None:\n",
    "        content = filterRouterContent(content, getRouter(path))\n",
    "\n",
    "    return metadata_dict.get(\"title\", \"\"), metadata_dict.get(\"description\", \"\"), content.strip()\n",
    "\n",
    "\n",
    "def traverseFolders(curr_path, df, version, indent = 0):\n",
    "    global chunk_count\n",
    "    for category in os.listdir(curr_path):\n",
    "        path = os.path.join(curr_path, category)\n",
    "        # print(\"\\t\" * indent + path)\n",
    "        \n",
    "        output_path = getOutputPath(path)\n",
    "        if os.path.isdir(path):\n",
    "            # Check if same output directory exists?\n",
    "            if not os.path.isdir(output_path):\n",
    "                os.mkdir(output_path)\n",
    "            df = traverseFolders(path, df, version, indent + 1)\n",
    "        else:\n",
    "            try:\n",
    "                title, description, content = processFile(path)\n",
    "                \n",
    "                # # We saw that the content with single line is not much useful for us.\n",
    "                # if content is not None and len(content.split(\"\\n\")) > 1:\n",
    "                if content is not None:\n",
    "                    # Will be helpful for next step when chunking\n",
    "                    if not content.startswith(\"#\"):\n",
    "                        content = f\"# {title}\\n\\n\" + content\n",
    "\n",
    "                    with open(output_path, 'w', encoding='utf-8') as fp:\n",
    "                        fp.write(content)\n",
    "\n",
    "                    chunks = chunk_markdown(content)\n",
    "                    num_chunks = len(chunks)\n",
    "                    chunk_count += num_chunks\n",
    "                    chunks_df = pd.DataFrame({\n",
    "                        'path': [path[len(extracted_data) + len(version) + 2:]] * num_chunks, \n",
    "                        'title': [title] * num_chunks,\n",
    "                        'description': [description] * num_chunks,\n",
    "                        'content': chunks\n",
    "                    })\n",
    "\n",
    "                    df = pd.concat([df, chunks_df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed for file: {path}\")\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For version: v15.1.0\n",
      "Min Content Length: 7, Max Content Length: 461\n",
      "Exceeding Chunk Size: 60/2719\n",
      "Files processed: (2719, 6), Chunk Count: 2719\n",
      "--------------------------------------------------\n",
      "For version: v15.0.0\n",
      "Min Content Length: 7, Max Content Length: 461\n",
      "Exceeding Chunk Size: 60/2594\n",
      "Files processed: (2594, 6), Chunk Count: 2594\n",
      "--------------------------------------------------\n",
      "For version: v14.0.0\n",
      "Min Content Length: 7, Max Content Length: 455\n",
      "Exceeding Chunk Size: 39/1978\n",
      "Files processed: (1978, 6), Chunk Count: 1978\n",
      "--------------------------------------------------\n",
      "For version: v14.2.0\n",
      "Min Content Length: 7, Max Content Length: 456\n",
      "Exceeding Chunk Size: 46/2368\n",
      "Files processed: (2368, 6), Chunk Count: 2368\n",
      "--------------------------------------------------\n",
      "For version: v14.1.0\n",
      "Min Content Length: 7, Max Content Length: 455\n",
      "Exceeding Chunk Size: 41/2185\n",
      "Files processed: (2185, 6), Chunk Count: 2185\n",
      "--------------------------------------------------\n",
      "For version: v13.5.0\n",
      "Min Content Length: 7, Max Content Length: 455\n",
      "Exceeding Chunk Size: 40/1930\n",
      "Files processed: (1930, 6), Chunk Count: 1930\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for version in os.listdir(extracted_data):\n",
    "    chunk_count = 0\n",
    "    if not os.path.exists(os.path.join(output_dir, version)):\n",
    "        os.mkdir(os.path.join(output_dir, version))\n",
    "\n",
    "    print(\"For version:\", version)\n",
    "    df = pd.DataFrame(columns=['path', 'title', 'description', 'content'])\n",
    "    df = traverseFolders(os.path.join(extracted_data, version), df, version)\n",
    "    df['version'] = version\n",
    "    df.to_csv(f\"{staging_data}/{version[1:]}.csv\", index=False)\n",
    "    df = pd.read_csv(f\"{staging_data}/{version[1:]}.csv\")\n",
    "\n",
    "    df['length'] = df['content'].apply(lambda x: len(x.split()))\n",
    "    print(f\"Min Content Length: {min(df['length'])}, Max Content Length: {max(df['length'])}\")\n",
    "    print(f\"Exceeding Chunk Size: {df[df['length'] > 385].shape[0]}/{df.shape[0]}\")\n",
    "    print(f\"Files processed: {df.shape}, Chunk Count: {chunk_count}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description', 'nav_title', 'related', 'title', 'version'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Introduction\n",
      "\n",
      "Welcome to the Next.js documentation!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## What is Next.js?\n",
      "\n",
      "Next.js is a React framework for building full-stack web applications. You use React Components to build user interfaces, and Next.js for additional features and optimizations.\n",
      "\n",
      "Under the hood, Next.js also abstracts and automatically configures tooling needed for React, like bundling, compiling, and more. This allows you to focus on building your application instead of spending time with configuration.\n",
      "\n",
      "Whether you're an individual developer or part of a larger team, Next.js can help you build interactive, dynamic, and fast React applications.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## Main Features\n",
      "\n",
      "Some of the main Next.js features include:\n",
      "\n",
      "| Feature                                                                  | Description                                                                                                                                                                                      |\n",
      "| ------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
      "| [Routing](/docs/app/building-your-application/routing)                   | A file-system based router built on top of Server Components that supports layouts, nested routing, loading states, error handling, and more.                                                    |\n",
      "| [Rendering](/docs/app/building-your-application/rendering)               | Client-side and Server-side Rendering with Client and Server Components. Further optimized with Static and Dynamic Rendering on the server with Next.js. Streaming on Edge and Node.js runtimes. |\n",
      "| [Data Fetching](/docs/app/building-your-application/data-fetching)       | Simplified data fetching with async/await in Server Components, and an extended `fetch` API for request memoization, data caching and revalidation.                                              |\n",
      "| [Styling](/docs/app/building-your-application/styling)                   | Support for your preferred styling methods, including CSS Modules, Tailwind CSS, and CSS-in-JS                                                                                                   |\n",
      "| [Optimizations](/docs/app/building-your-application/optimizing)          | Image, Fonts, and Script Optimizations to improve your application's Core Web Vitals and User Experience.                                                                                        |\n",
      "| [TypeScript](/docs/app/building-your-application/configuring/typescript) | Improved support for TypeScript, with better type checking and more efficient compilation, as well as custom TypeScript Plugin and type checker.                                                 |\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## How to Use These Docs\n",
      "\n",
      "On the left side of the screen, you'll find the docs navbar. The pages of the docs are organized sequentially, from basic to advanced, so you can follow them step-by-step when building your application. However, you can read them in any order or skip to the pages that apply to your use case.\n",
      "\n",
      "On the right side of the screen, you'll see a table of contents that makes it easier to navigate between sections of a page. If you need to quickly find a page, you can use the search bar at the top, or the search shortcut (`Ctrl+K` or `Cmd+K`).\n",
      "\n",
      "To get started, checkout the [Installation](/docs/getting-started/installation) guide.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## App Router vs Pages Router\n",
      "\n",
      "Next.js has two different routers: the App Router and the Pages Router. The App Router is a newer router that allows you to use React's latest features, such as Server Components and Streaming. The Pages Router is the original Next.js router, which allowed you to build server-rendered React applications and continues to be supported for older Next.js applications.\n",
      "\n",
      "At the top of the sidebar, you'll notice a dropdown menu that allows you to switch between the **App Router** and the **Pages Router** features. Since there are features that are unique to each directory, it's important to keep track of which tab is selected.\n",
      "\n",
      "The breadcrumbs at the top of the page will also indicate whether you're viewing App Router docs or Pages Router docs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## Pre-Requisite Knowledge\n",
      "\n",
      "Although our docs are designed to be beginner-friendly, we need to establish a baseline so that the docs can stay focused on Next.js functionality. We'll make sure to provide links to relevant documentation whenever we introduce a new concept.\n",
      "\n",
      "To get the most out of our docs, it's recommended that you have a basic understanding of HTML, CSS, and React. If you need to brush up on your React skills, check out our [Next.js Foundations Course](/learn/foundations/about-nextjs), which will introduce you to the fundamentals.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## Accessibility\n",
      "\n",
      "For optimal accessibility when using a screen reader while reading the docs, we recommend using Firefox and NVDA, or Safari and VoiceOver.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "# Introduction\n",
      "## Join our Community\n",
      "\n",
      "If you have questions about anything related to Next.js, you're always welcome to ask our community on [GitHub Discussions](https://github.com/vercel/next.js/discussions), [Discord](https://discord.com/invite/bUG2bvbtHy), [Twitter](https://twitter.com/nextjs), and [Reddit](https://www.reddit.com/r/nextjs).\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\n",
    "with open(\"./processedDocs/v14.0.0/index.mdx\", 'r') as fp:\n",
    "    content = fp.read()\n",
    "\n",
    "chunks = chunk_markdown(content)\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
